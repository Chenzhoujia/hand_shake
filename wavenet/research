行数可能有轻微的偏移（因为理解代码的过程中，有一些添加）

(1) 工程理解
->main,train.py:255
->loss,model.py:626
    在wavenet的命名空间下
    按照https://blog.csdn.net/dcrmg/article/details/79780331中的方法构建了网络的输入。
    最终在start_queue_runners命令中启动多线程读取样本，入队，读到当前的sess中，这时网络已经搭建完毕

->main,train.py:255
->loss,model.py:629
    原始输入是[1 61114 1] ,原始输出是[1 55997 256]，第二维度的数值取决于音频的长短，输入输出之间的差是感受野的大小，固定为5117，第一维度是batch，最后一个维度是数据特征维度
    原始输入首先经过了一个编码操作,将（基本都在-0.4～0.4之间）的浮点波形变成0~255的整数（这个操作中有对小波形的保留处理，其背后的原理，是否有参考价值？）[1 61114  1]
    接下来是一个global condition的操作也具有参考价值（暂不考虑）
    接下来是one_hot编码[1 61114  256]
    最后切断网络输入的最后一个样本以保持因果关系，网络输入搞定[1 61113  256]

->main,train.py:255
->loss,model.py:645
->_create_network,model.py:401
    从WaveNetModel对象中取出相应的变量[2,256,32]作为filter（filters的格式为：[filter_width, in_channels, out_channels]）,执行1D卷积操作：tf.nn.conv1d，步长为1，不做填充
    切掉输出结尾处多余的变量（应该不存在？因为没有padding，而且为什么是从尾部切的？反过来了吗），保证形成论文图2中的金字塔
->_create_network,model.py:411
    这里创建了论文中最核心的因果推理网络，一共有50层，其中跳跃链接是在->_create_dilation_layer,model.py:278中实现的。这个函数的输出有两个，一个是作为output，一个是将input传递下去，正如代码中的注释所示。
    time_to_batch与它的反操作是为了处理空洞卷积。
->_create_network,model.py
    最后的操作是把所有层的中间结果加起来，经过两个卷积后得到最终结果raw_output[1 55997 256]

(2) 工程改造
让人惊喜的是：(a)工程改造比较容易，主要就是
                (a.1)数据读取的工作
                (a.2)按照网络流程走一遍，分析网络结构，设计调试，首先需要考虑的就是感受野的层级
                (a.3)loss设计与调试。
            (b)hand graph的融入有了思路，global全局信息

(a.1) 在audio_reader这个文件中定义load_generated_pose函数，将文本文件中的pose数据读取出来，提供给线程thread_main，enqueue到当前sess中
    (a.1.1) self.queue = tf.PaddingFIFOQueue(queue_size,
                                         ['float32'],
                                         shapes=[(None, 1)])
                        在AudioReader对象的构造函数中定义了队列中一个数据的维度，需要改造成pose的大小
    (a.1.2) 接下来需要调整一些AudioReader创建时的参数，集中在 wavenet_params.json中定义。
          首先在不改变网络层数的基础上把感受野缩减到了52
          将网络的初始输入从256到60："quantization_channels": 60
    (a.1.3) 接下来需要调整一些网络训练的超参数，集中在train.py的开头处。
          首先SAMPLE_SIZE = None
    并run测试一下 发现没有问题，值得注意的是输入数据在前面扩充了52+2行全0的数据样本

(a.2) 主要是这个函数net = WaveNetModel和这个函数loss = net.loss
    (a.2.1) 首先将label和pose分开，分别传回去验证一下
    (a.2.2) 让pose走一遍 raw_output = self._create_network，思考其中的卷积操作的意义
            适当调整一下网络变量的大小，我们在 wavenet_params.json将中间层通道的大小调整为128。将最终输出通道数改为6

(a.3) 开启训练
    loss有正有负，并且爆炸。
    改进方案：
    输入归一化，label归一化，
    思考计算流程（为什么多了一个？），改学习率
    (a.3.1) 在读取数据时load_generated_pose，执行输入数据的归一化
    (a.3.2) loss的计算方式更换成L2, 学习率在超参数中，集中在train.py的开头处，暂时不修改。
    (a.3.3) 加载训练模型，并打印输出结果，看到了基本的效果
    (a.3.4) 无效label的去除，与归一化，感觉并不是很有必要
